{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашние задание по уроку 5 (SkillFactory)\n",
    "\n",
    "Slack: @Lek <br/>\n",
    "telegram: @AlexLekov <br/>\n",
    "\n",
    "### Оглавление:\n",
    "* [1. Подгрузка данных](#1)\n",
    "* [2. Очистка](#2)\n",
    "* [3. TfidfVectorizer](#3)\n",
    "* [4. Word2Vec](#4)\n",
    "* [5. Submit](#5)\n",
    "\n",
    "\n",
    "======================================================================================================================\n",
    "\n",
    "#### Описание задания\n",
    "\n",
    "Мы владельцы специфического Job-сайта и нам дали большой датасет вакансий. Одни вакансии нам интересны по своей тематике, другие не интересны (target 1 и 0 соответственно). Часть вакансий была размечена людскими ресурсами.\n",
    "  \n",
    "Ваша задача обучить классификатор, который на основе размеченной выборки умеет определять интересные вакансии для нашего сайта.\n",
    "\n",
    "* Метрика качества ROC_AUC.\n",
    "* ИСПОЛЬЗОВАТЬ ВНЕШНИЕ ДАННЫЕ С JOB-сайтов = ЗАПРЕЩЕНО\n",
    "* ИСПОЛЬЗОВАТЬ другие ВНЕШНИЕ ДАННЫЕ = только с разрешения организатора (смотри Discussion)\n",
    "* Результат засчитывается только при наличие кода, который этот результат повторяет\n",
    "* Участие командное\n",
    "\n",
    "#### PS:\n",
    "Обсудить урок и домашнее задание можно в нашем Slack-чате"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Поехали!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/start.jpg)\n",
    " <a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re # Регулярные выражения\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверк по CV , c перебором не только по фолдам но и по random_state:\n",
    "seeds=[1, 7, 42, 123, 2019]\n",
    "\n",
    "def cv_print (lr, X_train, y_train, seeds):\n",
    "    ''' clean print Cross Val Score + for random_state'''\n",
    "    cv_final=np.array([])\n",
    "    for random_state in seeds:\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "        cv = cross_val_score(lr, X_train, y_train, scoring='roc_auc', cv = skf, )\n",
    "        cv_final = np.append(cv_final, cv)\n",
    "    print('Mean: ', cv_final.mean())\n",
    "    print('Std: ', cv_final.std())\n",
    "    print('='*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"1\"></a>\n",
    "# 1. Подгрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv', sep='\\t', low_memory=False)\n",
    "test_df = pd.read_csv('data/test.csv', sep='\\t', low_memory=False)\n",
    "#data_df = pd.read_csv('data/other.csv', sep='\\t', low_memory=False)\n",
    "\n",
    "train_df['train'] = 1\n",
    "train_df['test'] = 0\n",
    "train_df.drop('id', inplace = True, axis = 1)\n",
    "\n",
    "test_df['train'] = 0\n",
    "test_df['test'] = 1\n",
    "test_df['target'] = 0\n",
    "test_df.drop('id', inplace = True, axis = 1)\n",
    "\n",
    "#data_df['target'] = 0\n",
    "#data_df['train'] = 0\n",
    "#data_df['test'] = 0\n",
    "\n",
    "df = test_df.append(train_df, sort=False).reset_index(drop=True)\n",
    "#df = df.append(data_df, sort=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Дизайнер-консультант мебели</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Обязанности:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Продавец-консультант (ТЦ на Пушкина)</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Обязанности&lt;/strong&gt;:&lt;/p&gt; &lt;p&gt;∙ конс...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Менеджер по продажам</td>\n",
       "      <td>&lt;p&gt;Торговый Дом «Форт» это ведущая компания Пе...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Продавец-консультант в магазин одежды (ТЦ Волн...</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Требуются продавцы консультанты в м...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Специалист по охране труда</td>\n",
       "      <td>&lt;strong&gt;Обязанности:&lt;/strong&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;осу...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Эксперт по обеспечению качества при сооружении...</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Обязанности:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Торговый представитель (Арзамас)</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Обязанности:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Заместитель генерального директора по производ...</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Обязанности:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Backend Rust developer</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Storiqa &lt;/strong&gt;- это площадка для...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Дизайнер-конструктор 3D</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Обязанности:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                        Дизайнер-консультант мебели   \n",
       "1               Продавец-консультант (ТЦ на Пушкина)   \n",
       "2                               Менеджер по продажам   \n",
       "3  Продавец-консультант в магазин одежды (ТЦ Волн...   \n",
       "4                         Специалист по охране труда   \n",
       "5  Эксперт по обеспечению качества при сооружении...   \n",
       "6                   Торговый представитель (Арзамас)   \n",
       "7  Заместитель генерального директора по производ...   \n",
       "8                             Backend Rust developer   \n",
       "9                            Дизайнер-конструктор 3D   \n",
       "\n",
       "                                         description  train  test  target  \n",
       "0  <p><strong>Обязанности:</strong></p> <ul> <li>...      0     1       0  \n",
       "1  <p><strong>Обязанности</strong>:</p> <p>∙ конс...      0     1       0  \n",
       "2  <p>Торговый Дом «Форт» это ведущая компания Пе...      0     1       0  \n",
       "3  <p><strong>Требуются продавцы консультанты в м...      0     1       0  \n",
       "4  <strong>Обязанности:</strong> <ul> <li> <p>осу...      0     1       0  \n",
       "5  <p><strong>Обязанности:</strong></p> <ul> <li>...      0     1       0  \n",
       "6  <p><strong>Обязанности:</strong></p> <ul> <li>...      0     1       0  \n",
       "7  <p><strong>Обязанности:</strong></p> <ul> <li>...      0     1       0  \n",
       "8  <p><strong>Storiqa </strong>- это площадка для...      0     1       0  \n",
       "9  <p><strong>Обязанности:</strong></p> <ul> <li>...      0     1       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 370179 entries, 0 to 370178\n",
      "Data columns (total 5 columns):\n",
      "name           370179 non-null object\n",
      "description    370179 non-null object\n",
      "train          370179 non-null int64\n",
      "test           370179 non-null int64\n",
      "target         370179 non-null int64\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 14.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113447 name\n",
      "249280 description\n",
      "2 train\n",
      "2 test\n",
      "2 target\n"
     ]
    }
   ],
   "source": [
    "# посмотрим количество уникальных значений для каждого столбца\n",
    "for colum in df.columns:\n",
    "    print(len(df[colum].value_counts()), colum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Менеджер по продажам              11643\n",
       "Продавец-консультант               9644\n",
       "Торговый представитель             9591\n",
       "Менеджер по работе с клиентами     6437\n",
       "Продавец-кассир                    2846\n",
       "Системный администратор            2792\n",
       "Мерчендайзер                       2762\n",
       "Маркетолог                         2108\n",
       "Программист 1С                     1897\n",
       "Менеджер по оптовым продажам       1868\n",
       "Name: name, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['name'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    106436\n",
       "1     93564\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"2\"></a>\n",
    "# 2. Очистка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### уберем html теги.\n",
    "Будем использовать библиотеку re.    \n",
    "Полная документация на данную библиотеку находится <a href=\"https://docs.python.org/2/library/re.html\">здесь</a>. Хорошее описание регулярных выражений <a href=\"https://ru.wikipedia.org/wiki/%D0%A0%D0%B5%D0%B3%D1%83%D0%BB%D1%8F%D1%80%D0%BD%D1%8B%D0%B5_%D0%B2%D1%8B%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D1%8F\">здесь</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_html(data):\n",
    "    clean_re = re.compile('<.*?>')\n",
    "    cleantext = re.sub(clean_re, '', data)\n",
    "    return cleantext\n",
    "\n",
    "df['description'] = df['description'].apply(lambda x: clean_html(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.name = df.name.str.lower()\n",
    "df.description = df.description.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>дизайнер-консультант мебели</td>\n",
       "      <td>обязанности:  работа с клиентом в салоне,выезд...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>продавец-консультант (тц на пушкина)</td>\n",
       "      <td>обязанности: ∙ консультирование покупателей по...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>менеджер по продажам</td>\n",
       "      <td>торговый дом «форт» это ведущая компания петер...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>продавец-консультант в магазин одежды (тц волн...</td>\n",
       "      <td>требуются продавцы консультанты в магазин женс...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>специалист по охране труда</td>\n",
       "      <td>обязанности:   осуществление контроля по соблю...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>эксперт по обеспечению качества при сооружении...</td>\n",
       "      <td>обязанности:    управление несоответствиями, в...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>торговый представитель (арзамас)</td>\n",
       "      <td>обязанности:  ведение и развитие существующей ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>заместитель генерального директора по производ...</td>\n",
       "      <td>обязанности:  доработка качества, в первую оче...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>backend rust developer</td>\n",
       "      <td>storiqa - это площадка для торговли физическим...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>дизайнер-конструктор 3d</td>\n",
       "      <td>обязанности:  адаптация дизайнов визуализация ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                        дизайнер-консультант мебели   \n",
       "1               продавец-консультант (тц на пушкина)   \n",
       "2                               менеджер по продажам   \n",
       "3  продавец-консультант в магазин одежды (тц волн...   \n",
       "4                         специалист по охране труда   \n",
       "5  эксперт по обеспечению качества при сооружении...   \n",
       "6                   торговый представитель (арзамас)   \n",
       "7  заместитель генерального директора по производ...   \n",
       "8                             backend rust developer   \n",
       "9                            дизайнер-конструктор 3d   \n",
       "\n",
       "                                         description  train  test  target  \n",
       "0  обязанности:  работа с клиентом в салоне,выезд...      0     1       0  \n",
       "1  обязанности: ∙ консультирование покупателей по...      0     1       0  \n",
       "2  торговый дом «форт» это ведущая компания петер...      0     1       0  \n",
       "3  требуются продавцы консультанты в магазин женс...      0     1       0  \n",
       "4  обязанности:   осуществление контроля по соблю...      0     1       0  \n",
       "5  обязанности:    управление несоответствиями, в...      0     1       0  \n",
       "6  обязанности:  ведение и развитие существующей ...      0     1       0  \n",
       "7  обязанности:  доработка качества, в первую оче...      0     1       0  \n",
       "8  storiqa - это площадка для торговли физическим...      0     1       0  \n",
       "9  обязанности:  адаптация дизайнов визуализация ...      0     1       0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"3\"></a>\n",
    "# 3. TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_preproc = df.query('train == 1').drop(['train','test'], axis=1)\n",
    "#df_test_preproc = df_preproc.query('test == 1').drop(['train','test'], axis=1)\n",
    "\n",
    "y = df_train_preproc.target.values\n",
    "X = df_train_preproc.drop(['target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfv_name = TfidfVectorizer(ngram_range=(1, 5), \n",
    "                            sublinear_tf=True,\n",
    "                           #stop_words = stopWords,\n",
    "                          max_features=45000 # если не много памяти можно уменьшить\n",
    "                          )\n",
    "tfv_desc = TfidfVectorizer(ngram_range=(1, 2),\n",
    "                            sublinear_tf=True,\n",
    "                           #stop_words = stopWords,\n",
    "                          max_features=80000\n",
    "                          )\n",
    "# про эту обработку рассказывали на lesson 5 - SkillFactory_20181211\n",
    "\n",
    "tfv_name_fit = tfv_name.fit(df.name)\n",
    "tfv_desc_fit = tfv_desc.fit(df.description)\n",
    "\n",
    "X_name = tfv_name_fit.transform(X.name)\n",
    "X_desc = tfv_desc_fit.transform(X.description)\n",
    "\n",
    "X_tf = hstack((X_name, X_desc)) # может знаете еще более эффективый по памяти способ/либу на слияния матриц?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tf, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  0.993614657690429\n",
      "Std:  0.00023150312275365136\n",
      "========================================\n",
      "Wall time: 2min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr = LogisticRegression(C=5, solver='sag', random_state=42)\n",
    "cv_print(lr, X_train, y_train, [42,1,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9938239421740739\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C=5, solver='sag', random_state=42) \n",
    "lr.fit(X_train, y_train)\n",
    "lr_1_predict_proba = lr.predict_proba(X_test)\n",
    "print(roc_auc_score(y_test, lr_1_predict_proba[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rf = RandomForestClassifier(n_estimators=1000, random_state=42, verbose=1, n_jobs=7)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_predict_proba = rf.predict_proba(X_test)\n",
    "print(roc_auc_score(y_test, rf_predict_proba[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=7)]: Done 186 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=7)]: Done 436 tasks      | elapsed: 16.8min\n",
      "[Parallel(n_jobs=7)]: Done 786 tasks      | elapsed: 30.3min\n",
      "[Parallel(n_jobs=7)]: Done 1000 out of 1000 | elapsed: 38.5min finished\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=7)]: Done 186 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=7)]: Done 436 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=7)]: Done 786 tasks      | elapsed:   12.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9927562500228956\n",
      "Wall time: 38min 48s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done 1000 out of 1000 | elapsed:   16.0s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf = RandomForestClassifier(n_estimators=1000, random_state=42, verbose=1, n_jobs=7)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_predict_proba = rf.predict_proba(X_test)\n",
    "print(roc_auc_score(y_test, rf_predict_proba[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_valid = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "params = {\n",
    "'objective':'binary',\n",
    "'num_leaves': 100,\n",
    "#'learning_rate': 0.1,\n",
    "'metric': 'auc',\n",
    "'bagging_fraction': 0.75,\n",
    "'bagging_freq': 10,\n",
    "#'feature_fraction':0.75,\n",
    "#'lambda_l1':5,\n",
    "#'lambda_l2':5,\n",
    "#'min_data_in_leaf': 500\n",
    "#'is_unbalance':True\n",
    "'seed':42,\n",
    "#'num_leaves':50, \n",
    "#'objective':'regression_l2', \n",
    "'learning_rate':0.01,\n",
    "'early_stopping_round':100,\n",
    "'max_bin':400,\n",
    "#'boosting':'dart'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:121: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[10]\tvalid_0's auc: 0.971752\n",
      "[20]\tvalid_0's auc: 0.977022\n",
      "[30]\tvalid_0's auc: 0.979891\n",
      "[40]\tvalid_0's auc: 0.981215\n",
      "[50]\tvalid_0's auc: 0.982281\n",
      "[60]\tvalid_0's auc: 0.982822\n",
      "[70]\tvalid_0's auc: 0.983084\n",
      "[80]\tvalid_0's auc: 0.983481\n",
      "[90]\tvalid_0's auc: 0.983726\n",
      "[100]\tvalid_0's auc: 0.984335\n",
      "[110]\tvalid_0's auc: 0.984556\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=2000,\n",
    "                valid_sets = lgb_valid,\n",
    "                verbose_eval = 10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9937994505620824\n"
     ]
    }
   ],
   "source": [
    "lgb_predict_proba = gbm.predict(X_test)\n",
    "print(roc_auc_score(y_test, lgb_predict_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_2 = {\n",
    "'objective':'binary',\n",
    "'num_leaves': 25,\n",
    "#'learning_rate': 0.1,\n",
    "'metric': 'auc',\n",
    "#'bagging_fraction': 0.75,\n",
    "#'bagging_freq': 10,\n",
    "#'feature_fraction':0.75,\n",
    "#'lambda_l1':5,\n",
    "#'lambda_l2':5,\n",
    "#'min_data_in_leaf': 500\n",
    "#'is_unbalance':True\n",
    "'seed':42,\n",
    "#'num_leaves':50, \n",
    "#'objective':'regression_l2', \n",
    "'learning_rate':0.01,\n",
    "'early_stopping_round':100,\n",
    "#'max_bin':400,\n",
    "#'boosting':'dart'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gbm_2 = lgb.train(params_2,\n",
    "                lgb_train,\n",
    "                num_boost_round=2000,\n",
    "                valid_sets = lgb_valid,\n",
    "                verbose_eval = 10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9935654681401638\n"
     ]
    }
   ],
   "source": [
    "lgb_2_predict_proba = gbm_2.predict(X_test)\n",
    "print(roc_auc_score(y_test, lgb_2_predict_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_predict roc_auc: \t 0.9945612954777295\n"
     ]
    }
   ],
   "source": [
    "mean_predict=np.zeros(len(lgb_predict_proba))\n",
    "for i in range(len(lgb_predict_proba)):\n",
    "    mean_predict[i]=(lr_1_predict_proba[i,1]+lgb_predict_proba[i]+rf_predict_proba[i,1])/3\n",
    "    \n",
    "print('Mean_predict roc_auc:', '\\t', roc_auc_score(y_test, mean_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_predict roc_auc: \t 0.9946070169007974\n"
     ]
    }
   ],
   "source": [
    "mean_predict=np.zeros(len(lgb_predict_proba))\n",
    "for i in range(len(lgb_predict_proba)):\n",
    "    mean_predict[i]=(lr_1_predict_proba[i,1]+lgb_predict_proba[i]+lgb_2_predict_proba[i]+rf_predict_proba[i,1])/4\n",
    "    \n",
    "print('Mean_predict roc_auc:', '\\t', roc_auc_score(y_test, mean_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit for submit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=5, solver='sag', random_state=42) \n",
    "lr.fit(X_tf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=7)]: Done 186 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=7)]: Done 436 tasks      | elapsed: 20.0min\n",
      "[Parallel(n_jobs=7)]: Done 786 tasks      | elapsed: 35.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 45min 15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done 1000 out of 1000 | elapsed: 45.2min finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf = RandomForestClassifier(n_estimators=1000, random_state=42, verbose=1, n_jobs=7)\n",
    "rf.fit(X_tf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "'objective':'binary',\n",
    "'num_leaves': 100,\n",
    "'bagging_fraction': 0.75,\n",
    "'bagging_freq': 10,\n",
    "'seed':42,\n",
    "'learning_rate':0.01,\n",
    "'max_bin':400,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2h 13min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgb_train = lgb.Dataset(X_tf, y)\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=2500,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_2 = {\n",
    "'objective':'binary',\n",
    "'num_leaves': 25,\n",
    "'seed':42,\n",
    "'learning_rate':0.01,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 38min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gbm_2 = lgb.train(params_2,\n",
    "                lgb_train,\n",
    "                num_boost_round=2500,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=7)]: Done 186 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=7)]: Done 436 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=7)]: Done 786 tasks      | elapsed:   35.4s\n",
      "[Parallel(n_jobs=7)]: Done 1000 out of 1000 | elapsed:   45.1s finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:447: UserWarning: Converting data to scipy sparse matrix.\n",
      "  warnings.warn('Converting data to scipy sparse matrix.')\n"
     ]
    }
   ],
   "source": [
    "lr_1_predict_proba = lr.predict_proba(X_tf)\n",
    "rf_predict_proba = rf.predict_proba(X_tf)\n",
    "lgb_predict_proba = gbm.predict(X_tf)\n",
    "lgb_2_predict_proba = gbm_2.predict(X_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_models4 = \\\n",
    "    pd.DataFrame([lr_1_predict_proba[:,1],lgb_predict_proba,lgb_2_predict_proba,rf_predict_proba[:,1]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_models4.to_csv('tfidf_train_models4.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_preproc = df.query('test == 1').drop(['train','test'], axis=1)\n",
    "#df_test_preproc = df_preproc.query('test == 1').drop(['train','test'], axis=1)\n",
    "\n",
    "y_k = df_test_preproc.target.values\n",
    "X_k = df_test_preproc.drop(['target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_name = tfv_name_fit.transform(X_k.name)\n",
    "X_test_desc = tfv_desc_fit.transform(X_k.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_kf_tf = hstack((X_test_name, X_test_desc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=7)]: Done 186 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=7)]: Done 436 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=7)]: Done 786 tasks      | elapsed:   33.1s\n",
      "[Parallel(n_jobs=7)]: Done 1000 out of 1000 | elapsed:   41.9s finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:447: UserWarning: Converting data to scipy sparse matrix.\n",
      "  warnings.warn('Converting data to scipy sparse matrix.')\n"
     ]
    }
   ],
   "source": [
    "lr_1_predict_proba = lr.predict_proba(X_kf_tf)\n",
    "rf_predict_proba = rf.predict_proba(X_kf_tf)\n",
    "lgb_predict_proba = gbm.predict(X_kf_tf)\n",
    "lgb_2_predict_proba = gbm_2.predict(X_kf_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_models4 = \\\n",
    "    pd.DataFrame([lr_1_predict_proba[:,1],lgb_predict_proba,lgb_2_predict_proba,rf_predict_proba[:,1]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_models4.to_csv('tfidf_test_models4.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"4\"></a>\n",
    "# 4. Word2Vec\n",
    "разработка by Anna  \n",
    "Slack: @Anna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "import gensim.sklearn_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_w2v_mean(word2vec, X):\n",
    "        return np.array([np.mean([word2vec[w] for w in words if w in word2vec]\n",
    "                    or [np.zeros(100)], axis=0) for words in X])\n",
    "    \n",
    "def transform_w2v_sum(word2vec, X):\n",
    "        return np.array([np.mean([word2vec[w] for w in words if w in word2vec]\n",
    "                    or [np.zeros(100)], axis=0) for words in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# уберем пунктуацию\n",
    "def clean_p(data):\n",
    "    clean_re = re.compile('[^\\w\\s]')\n",
    "    cleantext = re.sub(clean_re, ' ', data)\n",
    "    cleantext = cleantext.replace(\"  \", \" \")\n",
    "    cleantext = cleantext.replace(\"   \", \" \")\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'] = df['description'].apply(lambda x: clean_p(x))\n",
    "df['name'] = df['name'].apply(lambda x: clean_p(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'] = df['description'].str.split()\n",
    "df['name'] = df['name'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['Дизайнер', 'консультант', 'мебели']),\n",
       "       list(['Продавец', 'консультант', 'ТЦ', 'на', 'Пушкина']),\n",
       "       list(['Менеджер', 'по', 'продажам']), ...,\n",
       "       list(['Менеджер', 'по', 'продажам']),\n",
       "       list(['Торговый', 'представитель', 'в', 'Алматы']), list(['Швея'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['name'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучаем словарь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Word2Vec(size=200, min_count=1) #min_count - обуачть только слова встречающиеся n раз, лучше 1, но 2 быстрее\n",
    "model.build_vocab(df.description.values)\n",
    "model.train(df.description.values, total_examples=model.corpus_count, epochs=model.iter)\n",
    "w2v_desc = dict(zip(model.wv.index2word, model.wv.syn0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.39 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Word2Vec(size=100, min_count=1) #min_count - обуачть только слова встречающиеся n раз, лучше 1, но 2 быстрее\n",
    "model.build_vocab(df.name.values)\n",
    "model.train(df.name.values, total_examples=model.corpus_count, epochs=model.iter)\n",
    "w2v_name = dict(zip(model.wv.index2word, model.wv.syn0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.1092808 ,  3.1371803 ,  3.1112075 , -1.634942  ,  2.5531266 ,\n",
       "        1.2145935 ,  2.0634282 ,  2.384946  , -1.1940956 ,  0.21138524,\n",
       "       -1.3777215 , -0.7580045 , -0.5489473 ,  2.9192393 ,  0.29353264,\n",
       "        0.2148605 ,  0.22488508, -1.8911971 ,  1.7263371 , -4.0578938 ,\n",
       "       -2.670518  , -1.476629  , -0.72457963,  0.7752355 ,  1.7286243 ,\n",
       "       -0.0321142 , -0.51697206,  1.3388697 ,  0.3819138 , -1.2054482 ,\n",
       "        0.10867018, -1.4429821 ,  0.5105837 , -0.06046249, -0.7314942 ,\n",
       "       -0.22062474, -1.3847734 , -0.83774763,  1.2438725 ,  1.3739913 ,\n",
       "        2.6923735 , -0.5587024 ,  0.8099814 ,  0.9791361 , -1.3813494 ,\n",
       "        0.4592724 , -0.7144494 ,  0.23488039,  1.5531833 , -1.5729442 ,\n",
       "        2.4677796 , -1.4110694 , -3.7599382 ,  0.00666782,  1.0684805 ,\n",
       "        0.774604  , -2.1721253 , -0.67960525, -1.2658603 ,  0.5761809 ,\n",
       "        0.43903655,  0.29532656, -3.3248506 , -0.92592263, -0.03689454,\n",
       "       -0.5025313 , -0.754285  ,  2.0862854 ,  3.8509436 , -0.56268716,\n",
       "       -0.03755933,  1.1835661 ,  2.3740969 ,  2.1773963 ,  1.2826773 ,\n",
       "        0.81854194,  0.31966242,  2.3939617 , -1.2077563 ,  0.1159398 ,\n",
       "       -1.9465384 ,  0.24199288,  1.321221  ,  3.1212873 , -1.7631568 ,\n",
       "       -3.2726672 ,  3.6370394 , -0.66892123,  0.6172412 , -0.22182521,\n",
       "       -1.2765068 , -0.18648711,  0.30721876,  0.06972011,  0.23069076,\n",
       "        1.412707  ,  0.21006931, -0.14181648,  0.21231385,  2.089785  ,\n",
       "        1.2646155 , -0.1639466 ,  0.869469  , -5.3510485 ,  1.356844  ,\n",
       "        0.31735128,  3.2115624 ,  0.7454449 ,  0.82536614,  1.8650118 ,\n",
       "       -1.1253233 , -1.298349  ,  1.972614  ,  0.7903147 , -0.7895177 ,\n",
       "        0.5594468 ,  0.22694568,  1.8497163 , -1.9317333 ,  1.848899  ,\n",
       "       -0.37838742,  0.715358  ,  0.43000904, -1.5247843 ,  0.13431025,\n",
       "        0.9201156 , -1.759021  ,  0.16365492,  0.26987043,  1.5111622 ,\n",
       "        0.5195555 ,  1.6556565 , -0.9357804 , -0.20129646, -1.3790541 ,\n",
       "       -1.9111221 , -0.2002519 , -0.6690027 ,  0.04227394,  1.5161185 ,\n",
       "        0.08679832,  0.21357867, -0.84631604,  1.4459403 ,  1.4750184 ,\n",
       "       -0.23585448, -2.2829378 ,  3.7140968 , -1.010218  ,  0.8963566 ,\n",
       "       -0.37273744, -0.93378806, -0.25239623,  2.2811472 ,  1.0563335 ,\n",
       "       -2.0355139 , -1.61516   , -0.83438987, -1.8517772 , -2.1005397 ,\n",
       "       -0.25007576, -0.09152357, -0.93471104, -1.3418415 ,  3.513722  ,\n",
       "       -0.9369116 ,  0.49001   ,  0.62727296, -1.6023917 ,  4.207398  ,\n",
       "       -0.702957  ,  2.6579766 ,  2.7673047 , -1.0371631 ,  0.02653973,\n",
       "        2.163856  , -0.43121687,  2.373672  , -0.1613166 , -1.6566029 ,\n",
       "        2.7628953 , -0.26701322, -1.0074334 ,  1.0473118 ,  0.59054667,\n",
       "        1.4929887 ,  2.1487346 , -0.5764333 , -1.4423283 ,  0.33545536,\n",
       "        1.2811309 ,  2.4577174 ,  0.5763744 , -0.86374354, -0.9863943 ,\n",
       "        1.0420793 , -1.2444973 ,  2.6994963 ,  0.04469838,  2.1404517 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_desc['торговый']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_preproc = df.query('train == 1').drop(['train','test'], axis=1)\n",
    "#df_test_preproc = df_preproc.query('test == 1').drop(['train','test'], axis=1)\n",
    "\n",
    "y = df_train_preproc.target.values\n",
    "X = df_train_preproc.drop(['target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_desc_mean = transform_w2v_mean(w2v_desc, X.description)\n",
    "#tf_desc_sum = transform_w2v_sum(w2v_desc, X.description)\n",
    "\n",
    "tf_nam_mean = transform_w2v_mean(w2v_name, X.name)\n",
    "#tf_nam_sum = transform_w2v_sum(w2v_name, X.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200000, 200), (200000, 100))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_desc_mean.shape, tf_nam_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tf = np.hstack((tf_nam_mean,tf_desc_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tf, y, test_size = 0.25 ,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  0.9872178442907057\n",
      "Std:  0.0005390743086190204\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=42)\n",
    "cv_print(lr, X_train, y_train, [42,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_valid = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "params = {\n",
    "'objective':'binary',\n",
    "'num_leaves': 25,\n",
    "#'learning_rate': 0.1,\n",
    "'metric': 'auc',\n",
    "'bagging_fraction': 0.75,\n",
    "'bagging_freq': 10,\n",
    "#'feature_fraction':0.75,\n",
    "#'lambda_l1':5,\n",
    "#'lambda_l2':5,\n",
    "#'min_data_in_leaf': 500\n",
    "#'is_unbalance':True\n",
    "'seed':42,\n",
    "#'num_leaves':50, \n",
    "#'objective':'regression_l2', \n",
    "'learning_rate':0.02,\n",
    "'early_stopping_round':500,\n",
    "'max_bin':500,\n",
    "#'boosting':'dart'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[50]\tvalid_0's auc: 0.978418\n",
      "[100]\tvalid_0's auc: 0.983214\n",
      "[150]\tvalid_0's auc: 0.985796\n",
      "[200]\tvalid_0's auc: 0.987377\n",
      "[250]\tvalid_0's auc: 0.988452\n",
      "[300]\tvalid_0's auc: 0.989251\n",
      "[350]\tvalid_0's auc: 0.989807\n",
      "[400]\tvalid_0's auc: 0.990244\n",
      "[450]\tvalid_0's auc: 0.990596\n",
      "[500]\tvalid_0's auc: 0.990884\n",
      "[550]\tvalid_0's auc: 0.991144\n",
      "[600]\tvalid_0's auc: 0.991342\n",
      "[650]\tvalid_0's auc: 0.991493\n",
      "[700]\tvalid_0's auc: 0.991601\n",
      "[750]\tvalid_0's auc: 0.991714\n",
      "[800]\tvalid_0's auc: 0.991844\n",
      "[850]\tvalid_0's auc: 0.991938\n",
      "[900]\tvalid_0's auc: 0.992029\n",
      "[950]\tvalid_0's auc: 0.992107\n",
      "[1000]\tvalid_0's auc: 0.992184\n",
      "[1050]\tvalid_0's auc: 0.992246\n",
      "[1100]\tvalid_0's auc: 0.99231\n",
      "[1150]\tvalid_0's auc: 0.992366\n",
      "[1200]\tvalid_0's auc: 0.992401\n",
      "[1250]\tvalid_0's auc: 0.992428\n",
      "[1300]\tvalid_0's auc: 0.992478\n",
      "[1350]\tvalid_0's auc: 0.992507\n",
      "[1400]\tvalid_0's auc: 0.992556\n",
      "[1450]\tvalid_0's auc: 0.992606\n",
      "[1500]\tvalid_0's auc: 0.99265\n",
      "[1550]\tvalid_0's auc: 0.992683\n",
      "[1600]\tvalid_0's auc: 0.992719\n",
      "[1650]\tvalid_0's auc: 0.992755\n",
      "[1700]\tvalid_0's auc: 0.992793\n",
      "[1750]\tvalid_0's auc: 0.992826\n",
      "[1800]\tvalid_0's auc: 0.992845\n",
      "[1850]\tvalid_0's auc: 0.992866\n",
      "[1900]\tvalid_0's auc: 0.992894\n",
      "[1950]\tvalid_0's auc: 0.992919\n",
      "[2000]\tvalid_0's auc: 0.992943\n",
      "[2050]\tvalid_0's auc: 0.992966\n",
      "[2100]\tvalid_0's auc: 0.992994\n",
      "[2150]\tvalid_0's auc: 0.993024\n",
      "[2200]\tvalid_0's auc: 0.993051\n",
      "[2250]\tvalid_0's auc: 0.993065\n",
      "[2300]\tvalid_0's auc: 0.993078\n",
      "[2350]\tvalid_0's auc: 0.993093\n",
      "[2400]\tvalid_0's auc: 0.993102\n",
      "[2450]\tvalid_0's auc: 0.993123\n",
      "[2500]\tvalid_0's auc: 0.993142\n",
      "[2550]\tvalid_0's auc: 0.99316\n",
      "[2600]\tvalid_0's auc: 0.993173\n",
      "[2650]\tvalid_0's auc: 0.993193\n",
      "[2700]\tvalid_0's auc: 0.993209\n",
      "[2750]\tvalid_0's auc: 0.993224\n",
      "[2800]\tvalid_0's auc: 0.993228\n",
      "[2850]\tvalid_0's auc: 0.993236\n",
      "[2900]\tvalid_0's auc: 0.993247\n",
      "[2950]\tvalid_0's auc: 0.993258\n",
      "[3000]\tvalid_0's auc: 0.993263\n",
      "[3050]\tvalid_0's auc: 0.993276\n",
      "[3100]\tvalid_0's auc: 0.993278\n",
      "[3150]\tvalid_0's auc: 0.993292\n",
      "[3200]\tvalid_0's auc: 0.993295\n",
      "[3250]\tvalid_0's auc: 0.993306\n",
      "[3300]\tvalid_0's auc: 0.993309\n",
      "[3350]\tvalid_0's auc: 0.993316\n",
      "[3400]\tvalid_0's auc: 0.993316\n",
      "[3450]\tvalid_0's auc: 0.99333\n",
      "[3500]\tvalid_0's auc: 0.993336\n",
      "[3550]\tvalid_0's auc: 0.993345\n",
      "[3600]\tvalid_0's auc: 0.993356\n",
      "[3650]\tvalid_0's auc: 0.99336\n",
      "[3700]\tvalid_0's auc: 0.99336\n",
      "[3750]\tvalid_0's auc: 0.99337\n",
      "[3800]\tvalid_0's auc: 0.993378\n",
      "[3850]\tvalid_0's auc: 0.99339\n",
      "[3900]\tvalid_0's auc: 0.993399\n",
      "[3950]\tvalid_0's auc: 0.993403\n",
      "[4000]\tvalid_0's auc: 0.99341\n",
      "[4050]\tvalid_0's auc: 0.993402\n",
      "[4100]\tvalid_0's auc: 0.993403\n",
      "[4150]\tvalid_0's auc: 0.993414\n",
      "[4200]\tvalid_0's auc: 0.993427\n",
      "[4250]\tvalid_0's auc: 0.993438\n",
      "[4300]\tvalid_0's auc: 0.993444\n",
      "[4350]\tvalid_0's auc: 0.99345\n",
      "[4400]\tvalid_0's auc: 0.993453\n",
      "[4450]\tvalid_0's auc: 0.993454\n",
      "[4500]\tvalid_0's auc: 0.993455\n",
      "[4550]\tvalid_0's auc: 0.993457\n",
      "[4600]\tvalid_0's auc: 0.993458\n",
      "[4650]\tvalid_0's auc: 0.993459\n",
      "[4700]\tvalid_0's auc: 0.99347\n",
      "[4750]\tvalid_0's auc: 0.993468\n",
      "[4800]\tvalid_0's auc: 0.993475\n",
      "[4850]\tvalid_0's auc: 0.993479\n",
      "[4900]\tvalid_0's auc: 0.993487\n",
      "[4950]\tvalid_0's auc: 0.99349\n",
      "[5000]\tvalid_0's auc: 0.993494\n",
      "[5050]\tvalid_0's auc: 0.993501\n",
      "[5100]\tvalid_0's auc: 0.993505\n",
      "[5150]\tvalid_0's auc: 0.993507\n",
      "[5200]\tvalid_0's auc: 0.993513\n",
      "[5250]\tvalid_0's auc: 0.993525\n",
      "[5300]\tvalid_0's auc: 0.993524\n",
      "[5350]\tvalid_0's auc: 0.993529\n",
      "[5400]\tvalid_0's auc: 0.993529\n",
      "[5450]\tvalid_0's auc: 0.993523\n",
      "[5500]\tvalid_0's auc: 0.993526\n",
      "[5550]\tvalid_0's auc: 0.993538\n",
      "[5600]\tvalid_0's auc: 0.993545\n",
      "[5650]\tvalid_0's auc: 0.993546\n",
      "[5700]\tvalid_0's auc: 0.993549\n",
      "[5750]\tvalid_0's auc: 0.993552\n",
      "[5800]\tvalid_0's auc: 0.993561\n",
      "[5850]\tvalid_0's auc: 0.993567\n",
      "[5900]\tvalid_0's auc: 0.993571\n",
      "[5950]\tvalid_0's auc: 0.993579\n",
      "[6000]\tvalid_0's auc: 0.993584\n",
      "[6050]\tvalid_0's auc: 0.993587\n",
      "[6100]\tvalid_0's auc: 0.993586\n",
      "[6150]\tvalid_0's auc: 0.993589\n",
      "[6200]\tvalid_0's auc: 0.993587\n",
      "[6250]\tvalid_0's auc: 0.993588\n",
      "[6300]\tvalid_0's auc: 0.993594\n",
      "[6350]\tvalid_0's auc: 0.99359\n",
      "[6400]\tvalid_0's auc: 0.993596\n",
      "[6450]\tvalid_0's auc: 0.993598\n",
      "[6500]\tvalid_0's auc: 0.993605\n",
      "[6550]\tvalid_0's auc: 0.993606\n",
      "[6600]\tvalid_0's auc: 0.993605\n",
      "[6650]\tvalid_0's auc: 0.993612\n",
      "[6700]\tvalid_0's auc: 0.993619\n",
      "[6750]\tvalid_0's auc: 0.993625\n",
      "[6800]\tvalid_0's auc: 0.993628\n",
      "[6850]\tvalid_0's auc: 0.993618\n",
      "[6900]\tvalid_0's auc: 0.993619\n",
      "[6950]\tvalid_0's auc: 0.993622\n",
      "[7000]\tvalid_0's auc: 0.993625\n",
      "[7050]\tvalid_0's auc: 0.993628\n",
      "[7100]\tvalid_0's auc: 0.993632\n",
      "[7150]\tvalid_0's auc: 0.993635\n",
      "[7200]\tvalid_0's auc: 0.993632\n",
      "[7250]\tvalid_0's auc: 0.99364\n",
      "[7300]\tvalid_0's auc: 0.993634\n",
      "[7350]\tvalid_0's auc: 0.993634\n",
      "[7400]\tvalid_0's auc: 0.993628\n",
      "[7450]\tvalid_0's auc: 0.993631\n",
      "[7500]\tvalid_0's auc: 0.99363\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[7240]\tvalid_0's auc: 0.993643\n",
      "Wall time: 10min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=7500,\n",
    "                valid_sets = lgb_valid,\n",
    "                verbose_eval = 50,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit for submit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgb_train = lgb.Dataset(X_tf, y)\n",
    "params = {\n",
    "'objective':'binary',\n",
    "'num_leaves': 25,\n",
    "#'learning_rate': 0.1,\n",
    "#'metric': 'auc',\n",
    "'bagging_fraction': 0.75,\n",
    "'bagging_freq': 10,\n",
    "#'feature_fraction':0.75,\n",
    "#'lambda_l1':5,\n",
    "#'lambda_l2':5,\n",
    "#'min_data_in_leaf': 500\n",
    "#'is_unbalance':True\n",
    "'seed':42,\n",
    "#'num_leaves':50, \n",
    "#'objective':'regression_l2', \n",
    "'learning_rate':0.02,\n",
    "#'early_stopping_round':500,\n",
    "'max_bin':500,\n",
    "#'boosting':'dart'\n",
    "}\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=7000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_predict_proba = gbm.predict(X_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999945880324963\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y, lgb_predict_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_preproc = df.query('test == 1').drop(['train','test'], axis=1)\n",
    "#df_test_preproc = df_preproc.query('test == 1').drop(['train','test'], axis=1)\n",
    "\n",
    "y_k = df_test_preproc.target.values\n",
    "X_k = df_test_preproc.drop(['target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_desc_mean = transform_w2v_mean(w2v_desc, X_k.description)\n",
    "#tf_desc_sum = transform_w2v_sum(w2v_desc, X.description)\n",
    "\n",
    "tf_nam_mean = transform_w2v_mean(w2v_name, X_k.name)\n",
    "#tf_nam_sum = transform_w2v_sum(w2v_name, X.name)\n",
    "\n",
    "X_test_tf = np.hstack((tf_nam_mean,tf_desc_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_predict_proba = gbm.predict(X_test_tf)\n",
    "pd.DataFrame(lgb_predict_proba).to_csv('w2v_test_models1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"5\"></a>\n",
    "# 5. Oбъединяем решения и делаем Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_model_1_test = pd.read_csv('tfidf_test_models4.csv',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_model_1_test['w2v_lgb'] = pd.read_csv('w2v_test_models1.csv',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>w2v_lgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.982608</td>\n",
       "      <td>0.997645</td>\n",
       "      <td>0.987516</td>\n",
       "      <td>0.8745</td>\n",
       "      <td>0.983551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999489</td>\n",
       "      <td>0.999703</td>\n",
       "      <td>0.998780</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>0.999908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.989155</td>\n",
       "      <td>0.989016</td>\n",
       "      <td>0.980836</td>\n",
       "      <td>0.9590</td>\n",
       "      <td>0.986869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999718</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.998535</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>0.999907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.000840</td>\n",
       "      <td>0.005019</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>0.000087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.016907</td>\n",
       "      <td>0.005448</td>\n",
       "      <td>0.026112</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.003744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.998063</td>\n",
       "      <td>0.999001</td>\n",
       "      <td>0.996551</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.999985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.016659</td>\n",
       "      <td>0.430139</td>\n",
       "      <td>0.683200</td>\n",
       "      <td>0.5370</td>\n",
       "      <td>0.007741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.001213</td>\n",
       "      <td>0.004341</td>\n",
       "      <td>0.0680</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001176</td>\n",
       "      <td>0.004677</td>\n",
       "      <td>0.023571</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>0.001404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2       3   w2v_lgb\n",
       "0  0.982608  0.997645  0.987516  0.8745  0.983551\n",
       "1  0.999489  0.999703  0.998780  0.9970  0.999908\n",
       "2  0.989155  0.989016  0.980836  0.9590  0.986869\n",
       "3  0.999718  0.999841  0.998535  0.9920  0.999907\n",
       "4  0.000623  0.000840  0.005019  0.0360  0.000087\n",
       "5  0.016907  0.005448  0.026112  0.0010  0.003744\n",
       "6  0.998063  0.999001  0.996551  1.0000  0.999985\n",
       "7  0.016659  0.430139  0.683200  0.5370  0.007741\n",
       "8  0.000588  0.001213  0.004341  0.0680  0.000052\n",
       "9  0.001176  0.004677  0.023571  0.1390  0.001404"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_model_1_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.965164\n",
       "1    0.998976\n",
       "2    0.980975\n",
       "3    0.998000\n",
       "4    0.008514\n",
       "5    0.010642\n",
       "6    0.998720\n",
       "7    0.334948\n",
       "8    0.014839\n",
       "9    0.033966\n",
       "dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_5_model = pred_model_1_test.iloc[:, [0,1,2,3,4]].mean(axis=1)\n",
    "mean_5_model[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('data/test.csv', sep='\\t', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(columns=['id', 'target'],)\n",
    "submission['id'], submission['target'] = test_df.id.values, mean_5_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000</td>\n",
       "      <td>0.965164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200001</td>\n",
       "      <td>0.998976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200002</td>\n",
       "      <td>0.980975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200003</td>\n",
       "      <td>0.998000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200004</td>\n",
       "      <td>0.008514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    target\n",
       "0  200000  0.965164\n",
       "1  200001  0.998976\n",
       "2  200002  0.980975\n",
       "3  200003  0.998000\n",
       "4  200004  0.008514"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((170179, 3), (170179, 2))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape, submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission_v9_tfidf-w2v_mean5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовил: <b>Lek</b> <br/>\n",
    "Slack: @Lek <br/>\n",
    "telegram: @AlexLekov <br/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
